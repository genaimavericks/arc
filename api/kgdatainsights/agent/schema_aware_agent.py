import os
import json
import time
import hashlib
import threading
import traceback
import re
from pathlib import Path
from uuid import uuid4
from typing import Dict, List, Optional, Any

import httpx
from fastapi import Depends, HTTPException
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.chains import GraphCypherQAChain
from langchain.graphs import Neo4jGraph
from langchain.prompts import ChatPromptTemplate
from langchain_neo4j import (
    Neo4jChatMessageHistory
)

from .templates.foamfactory.cypher_prompt_template import CYPHER_GENERATION_PROMPT
from .templates.foamfactory.qa_prompt_template import QA_PROMPT
from .cache import Cache
from .cache import cacheable

from ...kginsights.database_api import get_database_config, parse_connection_params

# Load environment variables
load_dotenv()

# Output directories
OUTPUT_DIR = Path("runtime-data/output/kgdatainsights")
SCHEMA_DIR = OUTPUT_DIR / "schema"
PROMPT_DIR = OUTPUT_DIR / "prompts"

# Create directories if they don't exist
SCHEMA_DIR.mkdir(parents=True, exist_ok=True)
PROMPT_DIR.mkdir(parents=True, exist_ok=True)

class SchemaAwareGraphAssistant:
    """
    Enhanced Graph Assistant that automatically manages schemas and prompts.
    Extends the functionality of Neo4jGraphChatAssistant by adding schema and prompt management.
    """
    def __init__(self, source_id: str, session_id: str = None):
        """
        Initialize the Schema-Aware Graph Assistant.
        
        Args:
            source_id: The ID of the graph source to query
            session_id: Optional session ID for chat history, generated if not provided
        """
        self.source_id = source_id
        self.session_id = session_id or f"session_{uuid4()}"

        # Ensure we have the schema and prompt files
        self._ensure_schema()
        self._ensure_prompt()
        
        # Get Neo4j connection parameters from the database API
        self.connection_params = self._get_connection_params()
        print(f"Connection params: {self.connection_params}")
        
        # Initialize Neo4j Graph connection
        self.graph = Neo4jGraph(
            url=self.connection_params.get("uri"),
            username=self.connection_params.get("username"),
            password=self.connection_params.get("password"),
            database=self.connection_params.get("database", "neo4j"),
            enhanced_schema=True,
            refresh_schema=False  # Disable schema refresh to avoid APOC dependency
        )
        
        # Initialize Neo4j-backed chat history
        self.history = Neo4jChatMessageHistory(
            session_id=self.session_id,
            url=self.connection_params.get("uri"),
            username=self.connection_params.get("username"),
            password=self.connection_params.get("password"),
            database=self.connection_params.get("database", "neo4j")
        )
        
        # Load the custom prompts for this source
        self._load_prompts()
        
        # Initialize LLM first
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.2)
        
        # Initialize QA chain with Neo4j optimizations using modular LangChain pattern
        try:
            print(f"DEBUG: Initializing GraphCypherQAChain using langchain_neo4j pattern")
            
            # Create a structured chain configuration dictionary
            chain_config = {
                "llm": self.llm,
                "graph": self.graph,
                "verbose": True,
                "return_intermediate_steps": True,
                "allow_dangerous_requests": True
            }
            
            # Only add prompts if they are properly loaded
            if hasattr(self, 'cypher_prompt') and self.cypher_prompt:
                print('DEBUG: cypher prompt found')
                chain_config["cypher_prompt"] = self.cypher_prompt
            
            # QA prompt requires special handling because it relies on intermediate variables
            # that are generated by the chain itself (query and response)
            if hasattr(self, 'qa_prompt') and self.qa_prompt:
                print('DEBUG: qa prompt found - wrapping to handle intermediate variables')
                
                # We need to modify how the QA prompt is passed to work with GraphCypherQAChain
                # The chain internally generates 'query' and 'response' variables
                from langchain_core.prompts import PromptTemplate
                
                # Get the template string from our ChatPromptTemplate
                if hasattr(self.qa_prompt, 'template') and hasattr(self.qa_prompt.template, 'template'):
                    qa_template_str = self.qa_prompt.template.template
                    print(f"DEBUG: Using template string: {qa_template_str[:50]}...")
                    
                    # Create a proper PromptTemplate that GraphCypherQAChain can work with
                    # Based on the error, make sure we include 'query' as an input variable
                    # The langchain_neo4j GraphCypherQAChain specifically expects 'query' not 'question'
                    qa_prompt_template = PromptTemplate(
                        template=qa_template_str,
                        # Both 'query' and 'question' can refer to the same user input
                        # but the chain uses 'query' internally for the user question and for the Cypher query
                        input_variables=["query", "context"]
                    )
                    #chain_config["qa_prompt"] = qa_prompt_template
                else:
                    print(f"DEBUG: Using original QA prompt - may cause errors")
                    #chain_config["qa_prompt"] = self.qa_prompt
            
            # Initialize with the validated configuration
            self.chain = GraphCypherQAChain.from_llm(**chain_config)
            print(f"DEBUG: Successfully initialized GraphCypherQAChain")
            
        except Exception as e:
            print(f"ERROR: GraphCypherQAChain initialization failed: {str(e)}")
            print(f"DEBUG: Error details: {traceback.format_exc()}")        
        
        # Initialize cache
        self.cache = Cache()
    
    def _get_connection_params(self) -> dict:
        """
        Get connection parameters for the specified source from the database API.
        
        Returns:
            dict: Connection parameters including uri, username, password, and database
        """
        try:
            # Get the full database configuration
            config = get_database_config()
            
            # Get the specific graph configuration
            graph_config = config.get(self.source_id, {})
            
            if not graph_config:
                print(f"WARNING: No configuration found for source '{self.source_id}' in neo4j.databases.yaml")
                # Try to use default configuration if available
                graph_config = config.get("default", {})
                if graph_config:
                    print(f"INFO: Using 'default' Neo4j configuration as fallback for '{self.source_id}'")
                else:
                    print(f"ERROR: No fallback configuration found for '{self.source_id}'")
            
            # Parse the connection parameters
            params = parse_connection_params(graph_config)
            
            # Validate and log the parameters
            if not params:
                print(f"ERROR: Failed to parse connection parameters for '{self.source_id}'")
                return {
                    "uri": None,
                    "username": None,
                    "password": None,
                    "database": None
                }
            
            # Log the connection parameters (hide password)
            conn_debug = {
                "uri": params.get("uri"),
                "username": params.get("username"),
                "database": params.get("database"),
                "password": "*****" if params.get("password") else None
            }
            print(f"DEBUG: Neo4j connection parameters for '{self.source_id}': {conn_debug}")
            
            # Validate the essential parameters
            if not params.get("uri"):
                print(f"ERROR: Missing Neo4j URI for source '{self.source_id}'")
            
            return params
            
        except Exception as e:
            print(f"ERROR: Failed to get connection params for {self.source_id}: {str(e)}")
            print(f"DEBUG: Stack trace: {traceback.format_exc()}")
            return {
                "uri": None,
                "username": None,
                "password": None,
                "database": None
            }
    
    def _ensure_schema(self) -> None:
        """Check if schema exists, fetch and save if needed, deleting invalid existing files."""
        try:
            SCHEMA_DIR.mkdir(parents=True, exist_ok=True)
            schema_file = SCHEMA_DIR / f"schema_{self.source_id}.json"

            # --- Check and delete existing invalid file ---
            if schema_file.exists():
                try:
                    with open(schema_file, 'r') as f:
                        # Try loading to check if it's valid JSON at least
                        existing_schema = json.load(f)
                        # Check if it's a dictionary
                        if not isinstance(existing_schema, dict):
                            print(f"WARNING: Existing schema file {schema_file} is not a dictionary. Deleting.")
                            schema_file.unlink() # Delete if not a dict
                except (json.JSONDecodeError, Exception) as e:
                     # Catch errors during loading (corrupt file) or other issues
                     print(f"WARNING: Existing schema file {schema_file} is corrupt or invalid ({e}). Deleting.")
                     schema_file.unlink() # Delete if corrupt/unreadable
            # --- End check/delete ---

            # If schema file doesn't exist (or was just deleted), fetch and save it
            if not schema_file.exists():
                print(f"Schema file for {self.source_id} not found or was invalid. Fetching schema...")
                # Fetch attempt (this should already raise ValueError if it can't get a dict)
                schema = self._fetch_neo4j_schema()

                # Log the type after successful fetch (should always be dict here)
                print(f"DEBUG [ensure_schema]: Successfully fetched schema of type: {type(schema)}")

                # Save the schema (guaranteed to be a dict by _fetch_neo4j_schema)
                with open(schema_file, "w") as f:
                    json.dump(schema, f, indent=2)
                print(f"Schema saved to {schema_file}")
            else:
                 # If we reach here, the existing file was checked and deemed valid JSON dict
                 print(f"DEBUG: Using existing valid schema file: {schema_file}")

        except Exception as e:
            # Catch errors from fetching, saving, or other operations
            print(f"ERROR: Failed to ensure schema: {str(e)}")
            print(f"DEBUG: Stack trace: {traceback.format_exc()}")
            raise ValueError(f"Could not initialize schema for {self.source_id}: {str(e)}")
    
    def _fetch_neo4j_schema(self) -> Dict[str, Any]:
        """Fetch the Neo4j schema using the connection parameters, ensuring a dictionary is returned."""
        import traceback
        from langchain.graphs import Neo4jGraph
        
        # Get connection parameters
        params = self._get_connection_params()
        schema = None # Initialize schema

        # Log connection parameters (hide password)
        conn_debug = {
            "uri": params.get("uri"),
            "username": params.get("username"),
            "database": params.get("database", "neo4j"),
            "password": "*****" if params.get("password") else None
        }
        print(f"DEBUG: Attempting to connect to Neo4j with params: {conn_debug}")
        
        # Check if we have valid connection parameters
        if not params.get("uri"):
            print(f"WARNING: No valid Neo4j URI for {self.source_id}. Using mock schema.")
            return self._create_mock_schema()

        # --- Attempt 1: LangChain Enhanced Schema ---
        try:
            print(f"DEBUG: Creating Neo4jGraph connection for {self.source_id} (Attempt 1: Enhanced)")
            temp_graph = Neo4jGraph(
                url=params.get("uri"),
                username=params.get("username"),
                password=params.get("password"),
                database=params.get("database", "neo4j"),
                enhanced_schema=True,
                refresh_schema=True  # Enable schema refresh to get latest schema
            )

            print(f"DEBUG: Attempting to extract schema using enhanced method (requires APOC)")
            fetched_schema = temp_graph.schema
            print(f"DEBUG: Raw schema type from enhanced method: {type(fetched_schema)}")

            # Explicitly check if the fetched schema is a dictionary
            if isinstance(fetched_schema, dict):
                print(f"DEBUG: Schema successfully extracted using enhanced method and is a dictionary.")
                schema = fetched_schema # Assign valid schema
            else:
                print(f"WARNING: Enhanced schema extraction did not return a dictionary (type: {type(fetched_schema)}). Will try fallback.")
                # Do not return here, let it fall through to the fallback

        except Exception as e:
            print(f"ERROR: Enhanced schema extraction failed with exception: {str(e)}")
            print(f"DEBUG: Stack trace: ", traceback.format_exc())
            # Fall through to fallback

        # --- Attempt 2: Manual Fallback (if Attempt 1 failed or returned non-dict) ---
        if not isinstance(schema, dict): # Check if we still don't have a valid dict schema
            print("INFO: Falling back to manual schema extraction without APOC...")
            try:
                fallback_schema = self._fetch_schema_without_apoc(params)
                # Check the fallback result as well
                if isinstance(fallback_schema, dict):
                     print("DEBUG: Manual schema extraction successful and returned a dictionary.")
                     schema = fallback_schema # Assign valid schema from fallback
                else:
                     print(f"ERROR: Manual schema extraction fallback also failed to return a dictionary (type: {type(fallback_schema)}).")
                     # schema remains None or the non-dict value from attempt 1
            except Exception as fallback_e:
                print(f"ERROR: Manual schema extraction fallback failed with exception: {str(fallback_e)}")
                print(f"DEBUG: Fallback stack trace: ", traceback.format_exc())
                # schema remains None or the non-dict value from attempt 1

        # --- Final Check and Return ---
        if isinstance(schema, dict):
            return schema # Return the valid dictionary schema
        else:
            # If both methods failed to produce a dictionary, use mock schema
            print("WARNING: Both schema extraction methods failed. Using mock schema as last resort.")
            return self._create_mock_schema()
    
    def _fetch_schema_without_apoc(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Extract schema using direct Cypher queries without relying on APOC"""
        import traceback
        from neo4j import GraphDatabase
        
        print(f"DEBUG: Creating direct Neo4j driver connection for {self.source_id}")
        
        # Initialize driver to None for safe cleanup
        driver = None
        
        # Validate connection parameters
        uri = params.get("uri")
        if not uri:
            # If no URI is provided, create a mock schema for development/testing
            print(f"WARNING: No Neo4j URI available for {self.source_id}. Creating mock schema.")
            return self._create_mock_schema()
            
        username = params.get("username")
        password = params.get("password")
        database = params.get("database", "neo4j")
        
        try:
            # Create a direct driver connection
            print(f"DEBUG: Connecting to Neo4j at {uri}")
            driver = GraphDatabase.driver(
                uri,
                auth=(username, password) if username and password else None
            )
            
            # Test the connection before proceeding
            print(f"DEBUG: Testing Neo4j connection")
            driver.verify_connectivity()
            print(f"DEBUG: Connection verified successfully")
            
            schema = {
                "node_props": {},
                "rel_props": {},
                "relationships": []
            }
            
            with driver.session(database=database) as session:
                print(f"DEBUG: Opened Neo4j session successfully for database '{database}'")
                
                # 1. Get all node labels and their properties
                print(f"DEBUG: Executing query to extract node labels and properties")
                node_result = session.run("""
                MATCH (n)
                WITH DISTINCT labels(n) AS labels, keys(n) AS props
                UNWIND labels AS label
                RETURN label, collect(DISTINCT props) AS properties
                """)
                
                print(f"DEBUG: Processing node labels results")
                node_count = 0
                for record in node_result:
                    node_count += 1
                    label = record["label"]
                    props = [item for sublist in record["properties"] for item in sublist]
                    schema["node_props"][label] = list(set(props))
                print(f"DEBUG: Found {node_count} node labels in the database")
                
                # 2. Get all relationship types and their properties
                print(f"DEBUG: Executing query to extract relationship types and properties")
                rel_result = session.run("""
                MATCH ()-[r]-()
                WITH DISTINCT type(r) AS type, keys(r) AS props
                RETURN type, collect(DISTINCT props) AS properties
                """)
                
                print(f"DEBUG: Processing relationship types results")
                rel_count = 0
                for record in rel_result:
                    rel_count += 1
                    rel_type = record["type"]
                    props = [item for sublist in record["properties"] for item in sublist]
                    schema["rel_props"][rel_type] = list(set(props))
                print(f"DEBUG: Found {rel_count} relationship types in the database")
                
                # 3. Get relationship structure (source and target node types)
                print(f"DEBUG: Executing query to extract relationship structure")
                structure_result = session.run("""
                MATCH (src)-[r]->(dst)
                WITH DISTINCT labels(src) AS source_labels, type(r) AS rel_type, labels(dst) AS target_labels
                UNWIND source_labels AS source_label
                UNWIND target_labels AS target_label
                RETURN source_label, rel_type, target_label
                """)
                
                print(f"DEBUG: Processing relationship structure results")
                struct_count = 0
                for record in structure_result:
                    struct_count += 1
                    schema["relationships"].append({
                        "source": record["source_label"],
                        "target": record["target_label"],
                        "type": record["rel_type"]
                    })
                print(f"DEBUG: Found {struct_count} relationship structures in the database")
                
                print(f"DEBUG: Schema extraction completed successfully")
                return schema
                
        except Exception as e:
            print(f"ERROR: Manual schema extraction failed: {str(e)}")
            print(f"DEBUG: Stack trace: ", traceback.format_exc())
            # Return mock schema as fallback
            print(f"WARNING: Falling back to mock schema due to connection error")
            return self._create_mock_schema()
        
        finally:
            # Only try to close driver if it was successfully created
            if driver is not None:
                print(f"DEBUG: Closing Neo4j driver connection")
                try:
                    driver.close()
                except Exception as close_error:
                    print(f"WARNING: Error closing Neo4j driver: {str(close_error)}")
    
    def _create_mock_schema(self) -> Dict[str, Any]:
        """Create a mock schema for development and testing purposes"""
        print("DEBUG: Creating mock schema for development/testing")
        
        # Create a simple but realistic mock schema
        mock_schema = {
            "node_props": {
                "Person": ["name", "age", "email"],
                "Product": ["name", "price", "category"],
                "Order": ["id", "date", "total"]
            },
            "rel_props": {
                "PURCHASED": ["date", "quantity"],
                "REVIEWED": ["rating", "comment"],
                "SIMILAR_TO": ["score"]
            },
            "relationships": [
                {"source": "Person", "target": "Product", "type": "PURCHASED"},
                {"source": "Person", "target": "Product", "type": "REVIEWED"},
                {"source": "Product", "target": "Product", "type": "SIMILAR_TO"}
            ]
        }
        
        print("DEBUG: Successfully created mock schema")
        return mock_schema
        
    def _ensure_prompt(self) -> None:
        """Check if prompts exist, create and save if needed"""
        prompt_file = PROMPT_DIR / f"prompt_{self.source_id}.json"
        
        # If prompt file doesn't exist, create and save it
        if not prompt_file.exists():
            print(f"Prompt file for {self.source_id} not found. Creating prompts...")
            
            # Load the schema
            schema_file = SCHEMA_DIR / f"schema_{self.source_id}.json"
            if not schema_file.exists():
                self._ensure_schema()  # Make sure schema exists
            
            with open(schema_file, "r") as f:
                schema = json.load(f)
            
            # Generate prompts based on schema
            prompts = self._generate_prompts(schema)
            
            # Save the prompts to file
            with open(prompt_file, "w") as f:
                json.dump(prompts, f, indent=2)
                
            print(f"Prompts saved to {prompt_file}")
    
    def _generate_prompts(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        """Generate custom prompts using LLM based on the schema"""
        # Initialize an LLM for prompt generation
        prompt_generator_llm = ChatOpenAI(model="gpt-4", temperature=0.2)
        
        # Create a formatted schema summary
        schema_summary = self._extract_schema_summary(schema)
        
        # Prepare a schema-based prompt for the LLM
        schema_json = json.dumps(schema, indent=2)
        schema_json = schema_json.replace("\n", "").replace("\t", "").replace("{", "{{").replace("}", "}}")
        schema_summary_json = json.dumps(schema_summary, indent=2)
        
        # Define a system prompt for prompt generation
        system_prompt = """
        You are a Knowledge Graph expert tasked with creating optimal prompts for Neo4j graph database interactions. 
        You're being given a Neo4j graph schema in JSON format.
        
        Your job is to analyze the schema and generate two specialized prompt templates:
        1. A Cypher query generation prompt that will help an LLM convert natural language questions to Cypher queries
        2. A QA prompt that will help an LLM interpret Cypher query results and answer user questions
        
        These prompts should be tailored to the specific domain and structure of the knowledge graph as defined in the schema.
        """
        
        # Define the prompt for generating the Cypher generation prompt
        # IMPORTANT: Updated to use 'query' instead of 'question' for compatibility with GraphCypherQAChain
        cypher_prompt_instruction = """
        Please create a prompt template for generating Neo4j Cypher queries.
        
        The template should:
        1. Be tailored to the specific domain and structure of this knowledge graph
        2. CRITICALLY IMPORTANT: Any literal curly braces `{}` that appear in the final prompt text you generate, INCLUDING within example Cypher queries, MUST be escaped by using double curly braces `{{}}`. The only exception is the user query placeholder `{query}` itself.
        3. Include specific node labels, relationship types, and important properties from the schema
        4. Provide guidance on Neo4j Cypher best practices
        5. Include examples of good query patterns based on this schema
        6. CRITICALLY IMPORTANT: The final prompt MUST explicitly instruct the LLM to return ONLY a single raw Cypher query with NO explanations, NO headers, NO numbering, NO question repetition, NO backticks, and NO additional text of any kind
        7. The output must ONLY contain the executable Cypher query string without quotes or backticks around it
        8. VERY IMPORTANT: Generate Cypher queries that embed values directly. DO NOT use parameters like $name.
           - For string values, use single quotes: `{{name: 'Example Name'}}` (Note the double braces for the example itself!)
           - For numeric values, use them directly: `{{born: 1234}}` (Note the double braces!)
           - Ensure example Cypher queries you provide in the prompt follow this pattern, e.g.: `MATCH (p:Person {{name: 'Example Name'}})-[:ACTED_IN]->(m:Movie) RETURN m.title`
        
        9. For example queries, use the following format to make it clear what is the natural language and what is the Cypher code:

        Example 1: "<example_natural_language_query>"
        cypher: MATCH (n) RETURN n LIMIT 5
        
        Example 2: "<example_natural_language_query>"
        cypher: MATCH (p)-[r]->(m) RETURN p, r, m LIMIT 5
        
        10. Include placeholders for {query} where the user question will be inserted
        11. EXTREMELY IMPORTANT: The prompt should emphasize that the response should be ONLY the executable Cypher query with no additional text. The LLM must not include any of the following in its response:
            - NO "Simple Query:" or "Medium Query:" or "Complex Query:" headers
            - NO numbered lists like "1." or "2."
            - NO explanations before or after the query
            - NO backticks around the query
            - NO examples of multiple queries - just one single executable query
            - NO "Here's a Cypher query that..." text
            - NO "This query will..." explanatory text
        
        Do not use generic examples - use the actual node labels, relationship types and properties from the provided schema.
        Keep the prompt concise but comprehensive enough to guide accurate Cypher query generation.
        Focus on the most important entity types and relationships that would be commonly queried.
        
        IMPORTANT: Use {query} (not {{query}} or question) as the placeholder for the user's question, as this is required for compatibility with the GraphCypherQAChain.
        """
        
        # Define the prompt for generating the QA prompt
        # IMPORTANT: Updated to use simple {query} and {response} for compatibility with GraphCypherQAChain
        qa_prompt_instruction = """
        Please create a prompt template for answering questions based on Neo4j query results.
        
        The template should:
        1. Guide the response generation for questions about this specific knowledge graph
        2. Include domain-specific guidance based on the node types and relationships in the schema
        3. Provide instructions on how to interpret and present the query results
        4. Include placeholders for {query} and {context} 
        5. Use double curly braces({{{{) to escape single curly braces({{) except for {query} and {context} 
        6. Suggest how to handle common scenarios like empty results or large result sets
        
        Make the prompt specific to this graph's domain and structure, not generic.
        Include specifics about the most important node types and relationships in this particular graph.
        
        IMPORTANT: Use {query} (not {{query}}) for the user's question and generated Cypher query, and {context} (not {{context}}) for the query results, as these exact variable names are required for compatibility with the GraphCypherQAChain.
        """
        
        # Define the prompt for generating sample queries
        sample_queries_instruction = """
        Please generate 10-15 sample natural language questions that would be useful and insightful for this specific knowledge graph.
        
        The questions should:
        1. Reflect the actual structure and domain of this knowledge graph
        2. Use the real node labels, relationship types and properties from the schema
        3. Include a mix of simple and complex queries
        4. Focus on questions that would provide meaningful insights
        5. Be organized as a JSON array of strings
        
        Return ONLY the JSON array of sample questions, nothing else.
        """
        
        try:
            # Generate Cypher prompt template
            print(f"Generating Cypher prompt template for {self.source_id}...")
            cypher_messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Here is the Neo4j schema: {schema_json}\n\n{cypher_prompt_instruction}"}
            ]
            cypher_response = prompt_generator_llm.invoke(cypher_messages)
            cypher_prompt_template = cypher_response.content.strip()
            
            # Apply Neo4j property syntax escaping to prevent template variable confusion
            # cypher_prompt_template = self._escape_neo4j_properties(cypher_prompt_template)
            # print(f"DEBUG: Applied Neo4j property escaping to Cypher prompt template")
            
            # Generate QA prompt template
            print(f"Generating QA prompt template for {self.source_id}...")
            qa_messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Here is the Neo4j schema: {schema_json}\n\n{qa_prompt_instruction}"}
            ]
            qa_response = prompt_generator_llm.invoke(qa_messages)
            qa_prompt_template = qa_response.content.strip()
            
            # Apply Neo4j property syntax escaping to prevent template variable confusion
            # qa_prompt_template = self._escape_neo4j_properties(qa_prompt_template)
            # print(f"DEBUG: Applied Neo4j property escaping to QA prompt template")
            
            # Generate sample queries
            print(f"Generating sample queries for {self.source_id}...")
            sample_queries_messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Here is the Neo4j schema: {schema_json}\n\n{sample_queries_instruction}"}
            ]
            sample_queries_response = prompt_generator_llm.invoke(sample_queries_messages)
            
            # Extract JSON array from response
            try:
                # Attempt to parse the response as JSON
                sample_queries_text = sample_queries_response.content.strip()
                # Extract JSON array if it's wrapped in markdown code blocks or additional text
                if "```json" in sample_queries_text and "```" in sample_queries_text:
                    # Extract content between ```json and ```
                    json_content = sample_queries_text.split("```json")[1].split("```")[0].strip()
                    sample_queries = json.loads(json_content)
                elif "[" in sample_queries_text and "]" in sample_queries_text:
                    # Find the first [ and last ] in the text
                    start_idx = sample_queries_text.find("[")
                    end_idx = sample_queries_text.rfind("]")+1
                    json_content = sample_queries_text[start_idx:end_idx]
                    sample_queries = json.loads(json_content)
                else:
                    # Try parsing the whole response
                    sample_queries = json.loads(sample_queries_text)
            except Exception as e:
                print(f"Error parsing sample queries JSON: {e}")
                # Fallback to default sample queries
                sample_queries = [
                    "What are the main entities in this knowledge graph?",
                    "How many nodes and relationships are in the graph?",
                    "What is the overall structure of this knowledge graph?"
                ]
                # Add some basic queries using schema elements if available
                if schema_summary["node_labels"]:
                    label = schema_summary["node_labels"][0]
                    sample_queries.append(f"List all {label} nodes")
                    sample_queries.append(f"What are the key properties of {label} nodes?")
                if schema_summary["relationship_types"]:
                    rel_type = schema_summary["relationship_types"][0]
                    sample_queries.append(f"Show me relationships of type {rel_type}")
            
            # Create prompts dictionary
            prompts = {
                "source_id": self.source_id,
                "schema_summary": schema_json,
                "cypher_prompt": cypher_prompt_template,
                "qa_prompt": qa_prompt_template,
                "sample_queries": sample_queries
            }
            
            print(f"DEBUG: Created prompts with properly escaped Neo4j property syntax")
            
            return prompts
            
        except Exception as e:
            print(f"Error generating prompts with LLM: {e}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            
            # Instead of using fallback prompts, raise the exception to fail explicitly
            # This makes debugging easier by exposing the actual error
            raise RuntimeError(f"Failed to generate prompts for schema: {str(e)}")
    
    def _extract_schema_summary(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        """Extract a summary of the schema for prompt generation, handling the structure from schema fetching methods."""
        if not isinstance(schema, dict):
            raise ValueError("Schema must be a dictionary")

        node_labels = []
        relationship_types = set() # Use set for unique types
        properties_by_node = {}
        relationships_by_node = {} # Maps source label -> list of {"type": T, "target": L}
        property_list = set() # Use set for unique properties

        try:
            # --- Handle Node Properties ---
            # Check for Langchain format ('node_props' with list of dicts) or fallback format ('node_props' with list of strings)
            node_props_data = schema.get("node_props", {})
            if not isinstance(node_props_data, dict):
                print(f"WARNING: Expected 'node_props' to be a dict, got {type(node_props_data)}. Skipping node processing.")
            else:
                for label, props_info in node_props_data.items():
                    if not isinstance(label, str):
                        print(f"WARNING: Skipping non-string node label: {label}")
                        continue
                    node_labels.append(label)
                    current_props = []
                    if isinstance(props_info, list):
                        for prop_item in props_info:
                            prop_name = None
                            if isinstance(prop_item, dict) and isinstance(prop_item.get('property'), str):
                                 # Langchain format: {'property': 'name', 'type': 'STRING'}
                                prop_name = prop_item.get('property')
                            elif isinstance(prop_item, str):
                                # Fallback format: 'name'
                                prop_name = prop_item

                            if prop_name:
                                current_props.append(prop_name)
                                property_list.add(f"{label}.{prop_name}") # Add unique "Label.property"
                    else:
                         print(f"WARNING: Expected properties for label '{label}' to be a list, got {type(props_info)}")
                    properties_by_node[label] = sorted(list(set(current_props))) # Store unique, sorted props for the label

            # --- Handle Relationships ---
            relationships_data = schema.get("relationships", [])
            if not isinstance(relationships_data, list):
                print(f"WARNING: Expected 'relationships' to be a list, got {type(relationships_data)}. Skipping relationship processing.")
            else:
                 for rel_info in relationships_data:
                    if not isinstance(rel_info, dict):
                        print(f"WARNING: Expected relationship info to be a dict, got {type(rel_info)}")
                        continue

                    rel_type = rel_info.get("type")
                    # Langchain uses 'start', 'end'; Fallback uses 'source', 'target'
                    source = rel_info.get("source") or rel_info.get("start")
                    target = rel_info.get("target") or rel_info.get("end")

                    if isinstance(rel_type, str):
                        relationship_types.add(rel_type)

                    if isinstance(source, str) and isinstance(target, str) and isinstance(rel_type, str):
                        if source not in relationships_by_node:
                            relationships_by_node[source] = []
                        # Avoid adding duplicate relationship structures for the same source
                        rel_entry = {"type": rel_type, "target": target}
                        # Check existence based on content, not object identity
                        if not any(entry == rel_entry for entry in relationships_by_node[source]):
                             relationships_by_node[source].append(rel_entry)
                    else:
                        print(f"WARNING: Skipping relationship with invalid types/values: type={rel_type}({type(rel_type)}), source={source}({type(source)}), target={target}({type(target)})")

            # --- Handle Relationship Properties (Optional, add if needed for prompts) ---
            # rel_props_data = schema.get("rel_props", {})
            # ... similar processing logic as node_props if needed ...

        except Exception as e:
            print(f"ERROR: Failed to extract schema summary: {str(e)}")
            print(traceback.format_exc()) # Add traceback
            raise ValueError(f"Invalid schema format during summary extraction: {str(e)}")

        # Create schema summary
        final_property_list = sorted(list(property_list))
        return {
            "node_labels": sorted(list(set(node_labels))), # Ensure unique and sorted
            "relationship_types": sorted(list(relationship_types)), # Ensure unique and sorted
            "properties_by_node": properties_by_node,
            "relationships_by_node": relationships_by_node,
            # Limit properties sample AFTER sorting and making unique
            "property_list": final_property_list[:50]
        }

    
    def _load_prompts(self) -> None:
        """Load custom prompts for this source"""
        prompt_file = PROMPT_DIR / f"prompt_{self.source_id}.json"
        
        try:
            # Default to None initially to detect loading issues
            self.cypher_prompt = None
            self.qa_prompt = None
            
            print(f"DEBUG: Loading prompts from {prompt_file}")
            
            if prompt_file.exists():
                with open(prompt_file, "r") as f:
                    prompts = json.load(f)
                
                print(f"DEBUG: Prompt file loaded successfully")
                
                # Convert string prompts to ChatPromptTemplate objects if needed
                if "cypher_prompt" in prompts:
                    cypher_prompt_text = prompts.get("cypher_prompt")
                    # Check if it's already a structured object or a string
                    if isinstance(cypher_prompt_text, str):
                        print(f"DEBUG: Converting cypher_prompt string to ChatPromptTemplate")
                        # Check if the prompt starts with "Prompt:" or "Prompt Template:" and clean it
                        if cypher_prompt_text.startswith("Prompt:") or cypher_prompt_text.startswith("Prompt Template:"):
                            lines = cypher_prompt_text.split('\n')
                            # Skip the first line if it's just the "Prompt:" header
                            template_text = '\n'.join(lines[1:]).strip()
                            print(f"DEBUG: Cleaned prompt template from header")
                        else:
                            template_text = cypher_prompt_text
                            
                        # Fix all placeholder formats for compatibility with GraphCypherQAChain
                        # The key parameter expected by the chain is 'query', not 'question'
                        if "{{query}}" in template_text:
                            template_text = template_text.replace("{{query}}", "{query}")
                            print(f"DEBUG: Fixed {{query}} placeholder format")
                        
                        if "{{question}}" in template_text:
                            # Replace 'question' with 'query' for compatibility
                            template_text = template_text.replace("{{question}}", "{query}")
                            print(f"DEBUG: Replaced {{question}} with {{query}} for compatibility")
                        
                        self.cypher_prompt = ChatPromptTemplate.from_template(template_text)
                    else:
                        self.cypher_prompt = cypher_prompt_text
                else:
                    print(f"DEBUG: Using default CYPHER_GENERATION_PROMPT")
                    self.cypher_prompt = ChatPromptTemplate.from_template(CYPHER_GENERATION_PROMPT)
                
                if "qa_prompt" in prompts:
                    qa_prompt_text = prompts.get("qa_prompt")
                    # Check if it's already a structured object or a string
                    if isinstance(qa_prompt_text, str):
                        print(f"DEBUG: Converting qa_prompt string to ChatPromptTemplate")
                        # Check if the prompt starts with "Prompt:" or "Prompt Template:" and clean it
                        if qa_prompt_text.startswith("Prompt:") or qa_prompt_text.startswith("Prompt Template:"):
                            lines = qa_prompt_text.split('\n')
                            # Skip the first line if it's just the "Prompt:" header
                            template_text = '\n'.join(lines[1:]).strip()
                            print(f"DEBUG: Cleaned prompt template from header")
                        else:
                            template_text = qa_prompt_text
                            
                        # Fix all placeholder formats for compatibility with GraphCypherQAChain
                        # QA prompt should use 'query' and 'context' parameters
                        # LangChain specifically expects 'query' not 'question'
                        if "{{question}}" in template_text:
                            # Always replace 'question' with 'query' - this is critical
                            template_text = template_text.replace("{{question}}", "{query}")
                            print(f"DEBUG: Replaced {{question}} with {{query}} in QA prompt")
                            
                        if "{{query}}" in template_text:
                            template_text = template_text.replace("{{query}}", "{query}")
                            print(f"DEBUG: Fixed {{query}} format in QA prompt")
                            
                        if "{{context}}" in template_text:
                            template_text = template_text.replace("{{context}}", "{context}")
                            print(f"DEBUG: Fixed {{context}} format in QA prompt")
                            
                        if "{{response}}" in template_text:
                            # Also replace 'response' with 'context' as needed
                            template_text = template_text.replace("{{response}}", "{context}")
                            print(f"DEBUG: Replaced {{response}} with {{context}} in QA prompt")
                            
                        print(f"DEBUG: Fixed placeholders in QA prompt")
                        self.qa_prompt = ChatPromptTemplate.from_template(template_text)
                    else:
                        self.qa_prompt = qa_prompt_text
                else:
                    # Create a minimal QA prompt if none exists
                    print(f"DEBUG: Using default QA prompt template")
                    self.qa_prompt = ChatPromptTemplate.from_template(QA_PROMPT)
                
                # Load sample queries
                self.sample_queries = prompts.get("sample_queries", [])
            else:
                # Use defaults if no custom prompts available
                print(f"DEBUG: No prompt file found. Using defaults.")
                self.cypher_prompt = ChatPromptTemplate.from_template(CYPHER_GENERATION_PROMPT)
                self.qa_prompt = ChatPromptTemplate.from_template(QA_PROMPT)
                self.sample_queries = []
        except Exception as e:
            print(f"ERROR: Failed to load prompts: {str(e)}")
            print(f"DEBUG: {traceback.format_exc()}")
            
            
    def _debug_print_prompts(self):
        """Print debug information about the loaded prompts"""
        print("\n=== DEBUG: PROMPT INFORMATION ===")
        print(f"Cypher prompt type: {type(self.cypher_prompt)}")
        print(f"QA prompt type: {type(self.qa_prompt)}")
        
        # Check prompt template variable names
        if hasattr(self.cypher_prompt, 'template') and hasattr(self.cypher_prompt.template, 'variable_names'):
            print(f"Cypher prompt variables: {self.cypher_prompt.template.variable_names}")
        elif hasattr(self.cypher_prompt, 'input_variables'):
            print(f"Cypher prompt variables: {self.cypher_prompt.input_variables}")
        else:
            print("Cannot determine Cypher prompt variables")
            
        if hasattr(self.qa_prompt, 'template') and hasattr(self.qa_prompt.template, 'variable_names'):
            print(f"QA prompt variables: {self.qa_prompt.template.variable_names}")
        elif hasattr(self.qa_prompt, 'input_variables'):
            print(f"QA prompt variables: {self.qa_prompt.input_variables}")
        else:
            print("Cannot determine QA prompt variables")
        print("===================================\n")

    def _format_history(self) -> str:
        """Format last exchanges for context"""
        return "\n".join(
            f"{msg.content}" 
            for msg in self.history.messages[-5:] if msg.type == "ai"
        )

    @cacheable()
    def _extract_valid_cypher_query(self, llm_output: str) -> str:
        """
        Extract a valid Cypher query from the LLM's output.
        
        Args:
            llm_output: The raw output from the LLM containing Cypher query
            
        Returns:
            str: A clean, executable Cypher query
        """
        print(f"DEBUG: Extracting valid Cypher query from LLM output")
        print(f"DEBUG: Raw LLM output:\n{llm_output}")
        
        # List of valid Cypher keywords to check for
        valid_keywords = ["MATCH", "RETURN", "CREATE", "MERGE", "WITH", "CALL", "OPTIONAL", "UNWIND"]
        
        # Check if the output contains 'cypher query:' pattern
        try:
            match = re.search(r'cypher query:\s*(.+?)(?:\n|$)', llm_output, re.IGNORECASE)
            if match:
                query = match.group(1).strip()
                print(f"DEBUG: Found query using 'cypher query:' pattern: {query}")
                return query
        except Exception as e:
            print(f"WARNING: Error in 'cypher query:' pattern matching: {str(e)}")
        
        # Look for numbered queries in the output (e.g., "1. MATCH (n) RETURN n")
        try:
            # First, remove sections like "Simple Query:" or "Medium Query:" or "Complex Query:"
            # by splitting the text into sections and processing each section
            sections = re.split(r'(Simple|Medium|Complex)\s+Query:', llm_output)
            
            for i in range(1, len(sections), 2):  # Process each section after a header
                if i+1 < len(sections):
                    section_text = sections[i+1]
                    # Look for numbered queries in this section
                    numbered_matches = re.findall(r'\d+\.\s*(`?)([^`\n]+)(`?)', section_text)
                    for match in numbered_matches:
                        query_text = match[1].strip()
                        # Check if it starts with a valid Cypher keyword
                        if any(query_text.upper().startswith(keyword) for keyword in valid_keywords):
                            print(f"DEBUG: Found numbered query: {query_text}")
                            return query_text
        except Exception as e:
            print(f"WARNING: Error in numbered query extraction: {str(e)}")
        
        # Look for content within backticks
        try:
            matches = re.findall(r'`([^`]+)`', llm_output)
            if matches:
                # Find the first match that starts with a valid Cypher keyword
                for match in matches:
                    cleaned = match.strip()
                    if any(cleaned.upper().startswith(keyword) for keyword in valid_keywords):
                        print(f"DEBUG: Found query in backticks: {cleaned}")
                        return cleaned
        except Exception as e:
            print(f"WARNING: Error in backtick pattern matching: {str(e)}")
        
        # If we can't find a pattern, try to extract a valid Cypher query based on keywords
        try:
            lines = llm_output.split('\n')
            for line in lines:
                cleaned = line.strip()
                if any(cleaned.upper().startswith(keyword) for keyword in valid_keywords):
                    print(f"DEBUG: Found query by keyword: {cleaned}")
                    return cleaned
        except Exception as e:
            print(f"WARNING: Error in keyword extraction: {str(e)}")
        
        # If all else fails, return a simple query
        print(f"WARNING: Could not extract a valid Cypher query from LLM output. Using fallback query.")
        return "MATCH (n) RETURN labels(n) as labels, count(n) as count LIMIT 10"

    def _safe_execute_query(self, graph, query):
        """Safely execute a Neo4j query without risking recursion"""
        try:
            # Use the original query method directly
            original_query = graph.__class__.query
            return original_query(graph, query)
        except Exception as e:
            print(f"ERROR: Query execution failed: {str(e)}")
            return [{"error": f"Query failed: {str(e)}"}]

    def query(self, question: str) -> Dict[str, Any]:
        """Process user queries against the knowledge graph"""
        try:
            print(f"\n===== DEBUG: PROCESSING QUERY: '{question}' =====")
            # Add detailed diagnostic info about prompts
            self._debug_print_prompts()
            
            # Execute chain with context
            hist = self._format_history()
            print(f"HISTORY TO BE USED: {hist}")
            
            # Add schema awareness to the query
            start_time = time.time()
            
            # Use a direct approach to generate and execute Cypher
            try:
                # Step 1: Generate Cypher using the cypher_prompt
                cypher_gen_inputs = {"query": question}
                if hasattr(self.chain, "cypher_llm") and hasattr(self.chain, "cypher_prompt"):
                    print("DEBUG: Directly generating Cypher using the cypher prompt")
                    generated_cypher = self.chain.cypher_llm.invoke(
                        self.chain.cypher_prompt.format(**cypher_gen_inputs)
                    ).content
                    print(f"DEBUG: Generated Cypher:\n{generated_cypher}")
                    
                    # Step 2: Extract valid Cypher query
                    clean_cypher = self._extract_valid_cypher_query(generated_cypher)
                    
                    # Step 3: Execute the query
                    print(f"DEBUG: Executing extracted Cypher: {clean_cypher}")
                    try:
                        context = self._safe_execute_query(self.chain.graph, clean_cypher)
                    except Exception as exec_error:
                        print(f"DEBUG: Error executing extracted query: {str(exec_error)}")
                        # Try to extract a different query if the first one fails
                        fallback_cypher = "MATCH (n) RETURN labels(n) as labels, count(n) as count LIMIT 10"
                        print(f"DEBUG: Falling back to simple query: {fallback_cypher}")
                        context = self._safe_execute_query(self.chain.graph, fallback_cypher)
                    
                    # Step 4: Generate the final answer using the qa_prompt
                    qa_inputs = {"query": question, "context": context}
                    if hasattr(self.chain, "qa_llm") and hasattr(self.chain, "qa_prompt"):
                        print("DEBUG: Generating answer using QA prompt")
                        answer = self.chain.qa_llm.invoke(
                            self.chain.qa_prompt.format(**qa_inputs)
                        ).content
                        result = {"result": answer}
                    else:
                        result = {"result": f"Query results: {context}"}
                else:
                    # Fallback to standard chain invocation
                    print("DEBUG: Falling back to standard chain invocation")
                    result = self.chain.invoke({"query": question})
            except Exception as e:
                print(f"ERROR: Direct approach failed: {str(e)}")
                print(f"DEBUG: {traceback.format_exc()}")
                
                # Fallback to a simple query if everything else fails
                try:
                    print("DEBUG: Falling back to simple query")
                    fallback_query = "MATCH (n) RETURN labels(n) as labels, count(n) as count LIMIT 10"
                    context = self._safe_execute_query(self.chain.graph, fallback_query)
                    result = {
                        "result": f"I encountered an error processing your query: {str(e)}. \n\nHere's some basic information about the graph: {context}"
                    }
                except Exception as e2:
                    print(f"ERROR: Even simple fallback failed: {str(e2)}")
                    result = {
                        "result": f"I encountered multiple errors processing your query. The database might be unavailable or the query was malformed."
                    }
            
            query_time = time.time() - start_time
            print(f"Query completed in {query_time:.2f} seconds")
            
            # Persist conversation
            print(f"Persisting conversation: {result}")
            self.history.add_user_message(question)
            self.history.add_ai_message(result["result"])
            
            return result
        
        except Exception as e:
            print(f"Research error: {str(e)}")
            print(f"Full error traceback: {traceback.format_exc()}")
            return {"result": f"An error occurred while processing your query: {str(e)}. Please try again or contact support."}

    def __del__(self):
        # Close the cache connection when the object is garbage collected
        if hasattr(self, 'cache'):
            self.cache.close()

# Singleton-like behavior with dict of assistants by source_id
_assistants = {}
_lock = threading.Lock()

def get_schema_aware_assistant(source_id: str, session_id: str = None) -> SchemaAwareGraphAssistant:
    """
    Get a schema-aware assistant for the specified source_id.
    Creates a new assistant if one doesn't exist, otherwise returns the existing one.
    
    Args:
        source_id: ID of the graph source to query
        session_id: Optional session ID for chat history
        
    Returns:
        SchemaAwareGraphAssistant: The assistant for the source
    """
    # Create a unique key combining source_id and session_id
    key = f"{source_id}:{session_id}" if session_id else source_id
    
    try:
        with _lock:
            if key not in _assistants:
                # Log connection attempt for debugging
                print(f"DEBUG: Creating new schema-aware assistant for {source_id}")
                _assistants[key] = SchemaAwareGraphAssistant(source_id, session_id)
                print(f"DEBUG: Successfully created assistant for {source_id}")
            return _assistants[key]
    except Exception as e:
        # Log the error with detailed information
        error_message = f"Error creating schema-aware assistant for {source_id}: {str(e)}"
        print(f"ERROR: {error_message}")
        
        # Check for specific error types to provide better feedback
        if "Could not use APOC procedures" in str(e):
            print("DEBUG: APOC plugin issue detected. Ensure APOC is installed and configured.")
        elif "authentication failed" in str(e).lower() or "unauthorized" in str(e).lower():
            print("DEBUG: Authentication failed. Check Neo4j credentials.")
        elif "connection refused" in str(e).lower() or "unreachable" in str(e).lower():
            print("DEBUG: Connection failed. Check Neo4j server availability and network settings.")
            
        # Re-raise with a more informative message
        raise RuntimeError(f"Failed to initialize schema-aware assistant: {error_message}") from e
